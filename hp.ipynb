{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.keyboard_manager.command_shortcuts.add_shortcut('Ctrl-k','ipython.move-selected-cell-up')\n",
    "IPython.keyboard_manager.command_shortcuts.add_shortcut('Ctrl-j','ipython.move-selected-cell-down')\n",
    "IPython.keyboard_manager.command_shortcuts.add_shortcut('Shift-m','ipython.merge-selected-cell-with-cell-after')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from project_imports import *\n",
    "pd.options.display.notebook_repr_html = False\n",
    "pd.options.display.width = 120\n",
    "%matplotlib inline\n",
    "\n",
    "cachedir = 'cache/' # mkdtemp()\n",
    "memory = Memory(cachedir=cachedir, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import utils as ut; reload(ut);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    with open(\"src/txt/hp1.txt\",'rb') as f:\n",
    "        txt = f.read().decode(\"utf-8-sig\")\n",
    "    #     doc = Rtf15Reader.read(f)\n",
    "    t = txt[:60000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load, clean and parse text\n",
    "See `utils.py` for cleaning and parsing details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bksall = ut.BookSeries(7)\n",
    "\n",
    "with open('src/stops.txt', 'r') as f:\n",
    "    stops = set(l for l in f.read().splitlines() if l and not l.startswith('#'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I recently came across the [spaCy](https://spacy.io) library, which bills itself as a \"library for industrial-strength natural language processing in Python and Cython,\" and this seemed like a good opportunity to explore its capabilities. The starting point is a parsing function that parses, tags and detects entities all in one go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from spacy.en import English\n",
    "from spacy.parts_of_speech import ADJ\n",
    "%time nlp = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# bktks = {i: nlp(bktxt, tag=True, parse=True, entity=True) for i, bktxt in bks.txts.items()}\n",
    "%time bktksall = {i: nlp(bktxt, tag=True, parse=True, entity=True) for i, bktxt in bksall.txts.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll be writing a bunch of functions that take a list of tokens and returns a list of processed strings, numbers, etc. The following higher order functions are to facilitate applying these `[Token] -> [a]` functions to the entire Harry Potter series, returning a dataframe that keeps track of which book the processed value in a given row came from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tobooks(f: '(toks, int) -> DataFrame', bks=bktksall) -> DataFrame:\n",
    "    \"\"\"Apply a function `f` to all the tokens in each book,\n",
    "    putting the results into a DataFrame column, and adding\n",
    "    a column to indicate each book.\n",
    "    \"\"\"\n",
    "    return pd.concat([f(v, i) for i, v in bks.items()])\n",
    "\n",
    "def booker(f: 'toks -> [str]') -> '(toks, int) -> DataFrame':\n",
    "    @wraps(f)\n",
    "    def tobookdf(toks, bknum):\n",
    "        res = f(toks)\n",
    "        if np.ndim(res) == 1:\n",
    "            df = DataFrame(f(toks), columns=['Val'])\n",
    "        else:\n",
    "            df = res\n",
    "        df['Book'] = bknum\n",
    "        return df\n",
    "    return tobookdf\n",
    "    \n",
    "over_books = z.comp(partial(tobooks, bks=bktksall), booker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, a function that takes a stream of tokens and returns the first 2 words that are adjectives,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fst_2_nouns = lambda xs: list(it.islice((x.orth_ for x in xs if x.pos == ADJ), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "can be applied to each book in the series as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "over_books(fst_2_nouns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search for increasing complexity\n",
    "## 1. Average word and sentence length\n",
    "\n",
    "A first simple search would be to see if the average length of the words or sentences increases throughout the series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spanlen = lambda span: len([wd for wd in span if len(wd) > 1])\n",
    "sent_lensf = lambda parsed: [spanlen(sent) for sent in parsed.sents]\n",
    "wd_lensf = lambda parsed: [len(tok) for tok in parsed if len(tok) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wd_lensb = over_books(wd_lensf)\n",
    "sent_lensb = over_books(sent_lensf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def wd_sent_lens():\n",
    "    def agg_lens(lns):\n",
    "        return (lns\n",
    "              .groupby('Book')['Val'].agg(['mean', 'median', 'std'])\n",
    "              .rename(columns=str.capitalize))\n",
    "\n",
    "    wd_len = agg_lens(wd_lensb)\n",
    "    sent_len = agg_lens(sent_lensb)\n",
    "    \n",
    "    lens = {'Sentence_length': sent_len, 'Word_length': wd_len}\n",
    "    return pd.concat(lens.values(), axis=1, keys=lens.keys())\n",
    " \n",
    "wsls = wd_sent_lens()\n",
    "wsls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "wsls.Word_length['Mean'].plot(title='Average word length')\n",
    "plt.subplot(1, 2, 2)\n",
    "wsls.Sentence_length['Mean'].plot(title='Average sentence length');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There does appear to be an increasing trend for both average word and sentence length difference between the books, though the scale of the difference looks miniscule in light of the standard deviations within each book.\n",
    "\n",
    "One way to gauge the likelihood that the average word length difference between, say, books 1 and 2 is due to chance would be to   shuffle the labels a bunch of times, and each time calculate the difference in average word length. (See Jake VanderPlas' [Statistics for Hackers](https://speakerdeck.com/jakevdp/statistics-for-hackers) talk and [Tim Hesterberg's article](http://arxiv.org/abs/1411.5279) covering permutation tests for an explanation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sim_diff_(xs, N, aggfunc=np.mean, p=.5):\n",
    "    labs = nr.binomial(1, p, N)  # cheap shuffling approximation\n",
    "    g1 = aggfunc(xs[labs == 1])\n",
    "    g2 = aggfunc(xs[labs == 0])\n",
    "    return g2 - g1\n",
    "\n",
    "\n",
    "@memory.cache\n",
    "def sim_diff(xs, n1, aggfunc=np.mean, nsims=10, n_jobs=1):\n",
    "    N = len(xs)\n",
    "    p = n1 / N\n",
    "    xs = np.array(xs)\n",
    "    f = delayed(sim_diff_)\n",
    "    gen = (f(xs, N, aggfunc=aggfunc, p=p) for _ in range(nsims))\n",
    "    return Series(Parallel(n_jobs=n_jobs)(gen))\n",
    "\n",
    "\n",
    "def plot_perm_diffs(samps, actual=None, bka=2, bkb=1, subplt=1, xlabel=None):\n",
    "    t = ('Simulated and actual difference between books {bka} and {bkb}'\n",
    "         '\\nPermutation pvalue: {pv:.3%}; N={N:,.0f}'\n",
    "          .format(bka=bka, bkb=bkb, pv=ut.pvalue(actual, samps), N=len(samps)))\n",
    "    plt.subplot(1, 2, subplt, title=t)\n",
    "    samps.hist(bins=50)\n",
    "    plt.vlines(actual, *plt.ylim())\n",
    "    plt.legend(['Actual\\ndifference'], loc=2)\n",
    "    if xlabel is not None:\n",
    "        plt.xlabel(xlabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wd_lensb23 = wd_lensb.query('Book == [2, 3]')\n",
    "%time perm_wd_23 = sim_diff(wd_lensb23.Val, wd_lensb23.Book.value_counts(normalize=0)[2], nsims=10000, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wd_lensb12 = wd_lensb.query('Book == [1, 2]')\n",
    "%time perm_wd_12 = sim_diff(wd_lensb12.Val, wd_lensb12.Book.value_counts(normalize=0)[1], nsims=10000, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the following histogram of simulated word length differences shows, the difference is quite significant in the word lengths, despite what the large standard deviations first led me to believe. The trendline above shows an pronounced jump between books 1 & 2 which is reflected in the smallest possible p-value, but the permutation sampling shows that the jump between 2 and 3 is also significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 5))\n",
    "dw12 = wsls.Word_length.Mean[2] - wsls.Word_length.Mean[1]\n",
    "plot_perm_diffs(perm_wd_12, actual=dw12, bka=1, bkb=2, subplt=1, xlabel='Word length difference')\n",
    "\n",
    "dw23 = wsls.Word_length.Mean[3] - wsls.Word_length.Mean[2]\n",
    "plot_perm_diffs(perm_wd_23, actual=dw23, bka=2, bkb=3, subplt=2, xlabel='Word length difference')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The earlier trendline for sentence lengths is more ambiguous. While the word length immediately jumps following *The Sorcerer's Stone* and continues to increase in all but 2 cases, the sentence length bounces around a lot more. But there does seem to be a significant difference between the first four and the last three, which we can also test for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sent_lens_fst_snd = sent_lensb.copy()\n",
    "sent_lens_fst_snd['Part'] = '1-4'\n",
    "sent_lens_fst_snd.loc[sent_lensb.Book > 4, 'Part'] = '5-7'\n",
    "μ_ab = sent_lens_fst_snd.groupby('Part').Val.mean()\n",
    "\n",
    "n1 = sent_lens_fst_snd.Part.value_counts(normalize=0)['1-4']\n",
    "%time perm_sent_ab = sim_diff(sent_lens_fst_snd.Val, n1, nsims=10000, n_jobs=-1)\n",
    "del n1\n",
    "sent_lens12 = sent_lensb.query('Book == [1, 2]')\n",
    "%time perm_sent_12 = sim_diff(sent_lens12.Val, sent_lens12.Book.value_counts(normalize=0)[1], nsims=100000, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 5))\n",
    "dsab = μ_ab.ix['5-7'] - μ_ab.ix['1-4']\n",
    "plot_perm_diffs(perm_sent_ab, actual=dsab, bka='5-7', bkb='1-4', subplt=1, xlabel='Sentence length difference')\n",
    "\n",
    "ds12 = wsls.Sentence_length.Mean[2] - wsls.Sentence_length.Mean[1]\n",
    "plot_perm_diffs(perm_sent_12, actual=ds12, bka=1, bkb=2, subplt=2, xlabel='Sentence length difference')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that the difference between books 1 & 2 is very significant, though not as much as the difference between the first and second parts (as defined by 1-4 and 5-7). Thus we can, with reasonable confidence, reject the notion that the increase in word length and sentence length through the series is a statistical artifact that ocurred by chance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word complexity by frequency\n",
    "\n",
    "The lack of discernible difference in word/sentence length could be because even complex language is still largely composed of shorter, commoner words, highlighted by rarer, more complex words. A way to test this could be to somehow get a measure of the frequency of just the rarer words by counting, for example,  what percentage of the words only appear once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reg_words(parsed):\n",
    "    \"Non-capitalized words > 3 chars long that aren't stopwords\"\n",
    "    wds = [tok.orth_ for tok in parsed]\n",
    "    #wds = [tok.string.rstrip() for tok in parsed]\n",
    "    return [w for w in wds if len(w) > 3 and (w.lower() not in stops) and not w[0].isupper()]\n",
    "\n",
    "def wd_freqs(parsed):\n",
    "    vcs = Series(Counter(reg_words(parsed))).sort_values(ascending=False)\n",
    "    return vcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "uncwds = over_books(wd_freqs).reset_index(drop=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The folllowing shows the relative word frequency distribution. The first two numbers in the first column indicate that for book one, words appearing only 1 time account for 45.2% of all the word occurences, while words appearing twice account for 16.9%. If anything, it appears that the share of rare words (those appearing only once or twice) *decreases* with each book, rather than increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k = 10\n",
    "wdfreq = DataFrame({bknum: gdf.Val.value_counts(normalize=1)[:k]\n",
    "            for bknum, gdf in uncwds.groupby(['Book'])})\n",
    "wdfreq = (wdfreq * 100).round(1)\n",
    "wdfreq.columns.name, wdfreq.index.name = 'Book', 'Word_freq'\n",
    "wdfreq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cumulative share of words appearing 10 times or less also doesn't seem to indicate an increasing share of uncommon words, and if anything points to uncommon words being used more in the first three books, and deacreasing for the last four. (The following graph should be interpreted to say that, for example, 90% of the words in the first book are those that appear fewer than 11 times, while 86% of the words in book 5 occur fewer than 11 times)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wdfreq.apply(mc('cumsum')).ix[10].plot()\n",
    "plt.ylabel('% of words in each book\\n that appear 10 times or less');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word complexity by frequency in English language usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The frequency counting above, however, only counts words that are rare within the context of this series. Fortunateky, spaCy provides a log-probability score for each parsed word, based on its frequency in external corpora. These will be negative numbers such that a lower score indicates that a word is less common in English usage outside of Harry Potter. \"Low probability,\" \"low likelihood\" and \"less common\" are terms I'll use to describe words with low log-probability scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "probs = lambda x: [tok.prob for tok in x if tok.is_lower]\n",
    "prob_books = over_books(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def percentile(q: float) -> \"[float] -> int\":\n",
    "    def f(s):\n",
    "        return np.percentile(s, q)\n",
    "    f.__name__ = 'perc_{}'.format(q)\n",
    "    return f\n",
    "\n",
    "def show_freq(bookstats):\n",
    "    probstats = (bookstats.groupby('Book').Val\n",
    "                 .agg(['mean', 'std', 'median',\n",
    "                       percentile(5), percentile(25)])\n",
    "                .rename(columns=str.capitalize))\n",
    "    probstats[['Perc_5', 'Perc_25', 'Median', 'Mean']].plot(title='Word Frequency')\n",
    "    plt.xticks(range(1, 8));\n",
    "    return probstats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_freq(prob_books)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most drastic difference is in the frequency of the 95th percentile between first and second books. The graph shows that a typical word in the 95th percentile has a log probability of -13.3 in the first book and -13.8 in the second. The drop doesn't look that drastic, and there doesn't seem to be a discernable overall trend, either.\n",
    "\n",
    "Out of curiosity, it could be helpful to dig into what the probabilities look like for the first couple hundred least likely words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "probs1 = probs(bktksall[1])\n",
    "probs2 = probs(bktksall[2])\n",
    "# probs12 = probs1 + probs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def show_unc_word_trend():\n",
    "    n = 200\n",
    "    s1 = Series(probs1).sort_values(ascending=True).reset_index(drop=1)\n",
    "    s1[s1 < -12][:n].plot()\n",
    "    s2 = Series(probs2).sort_values(ascending=True).reset_index(drop=1)\n",
    "    s2[s2 < -12][:n].plot(title='Log probability for $n$ rarest words')\n",
    "    plt.legend(['Book 1', 'Book 2'])\n",
    "    \n",
    "plt.figure(figsize=(8, 5))\n",
    "show_unc_word_trend()\n",
    "plt.hlines([-18.25, -18.32], *plt.xlim(), linestyles='dashdot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting from the least common words, it looks like the part of the reason Book 2's words are less frequent is due to a few streaks of words that have log probabilities indicated by the dashed lines. The repetition of certain uncommon words in the story line could lead us to classify some text as more complex than we should. A solution would be to run the same plots on the probabilities of *unique* words in the texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_prob_id(toks) -> 'DataFrame[Prob, Id]':\n",
    "    return DataFrame([(tok.prob, tok.orth) for tok in toks if tok.is_lower], columns=['Prob', 'Id'])\n",
    " \n",
    "def unique_probs(toks):\n",
    "    \"Like `probs`, but drop duplicate words\"\n",
    "    df = get_prob_id(toks)\n",
    "    return df.drop_duplicates('Id').Prob.tolist()\n",
    "\n",
    "uprob_books = over_books(unique_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ufreq = show_freq(uprob_books)\n",
    "ufreq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the trend towards more complex words is much more pronounced, and looks as if it continues throughout the whole series, with book 5 having disproportionately many more complex words. As anyone who's read the series can tell, Book 5 (*Order of the Phoenix*) also stands out as being disproportionately longer in page numbers, as confirmed by the wordcount:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 5))\n",
    "wc = Series(z.valmap(len, bktksall))\n",
    "plt.subplot(1, 2, 1)\n",
    "wc.plot(title='Word count'); plt.ylim(0, None);\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(wc, ufreq.Mean);\n",
    "plt.title('Word likelihood vs word count')\n",
    "plt.ylabel('Mean log p'); plt.xlabel('Total word count');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...which could lead us to wonder whether the increasing complexity in word choice is simply an artifact of the length of the books (if the text were generated randomly from the same distribution, we would expect longer texts to include a greater number of unique and rarer words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_corrcoef(x=None, y=None, data=None):\n",
    "    sns.regplot(x=x, y=y, data=data, order=1)\n",
    "    plt.title('Corr. Coef.: {:.3f}'.format(stats.pearsonr(data[x], data[y])[0]))\n",
    "    plt.ylabel('Mean log p')\n",
    "    plt.xlabel('Total word count');\n",
    "    \n",
    "plot_corrcoef(x='Word_count', y='Mean', data=ufreq.assign(Word_count=wc))\n",
    "# sns.regplot(x='Word_count', y='Mean', data=ufreq.assign(Word_count=wc))\n",
    "# plt.title('Corr. Coef.: {:.3f}'.format(stats.pearsonr(ufreq.Mean, wc)[0]));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, the relationship between typical word appears to have a quite [log] linear relationship with word count. I'm not sure what relationship is to be expected, but it looks like it would be worthwhile to try and correct for document length in determining word complexity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def simgrowth(toks, nsims=20):\n",
    "    def simgrowth_():\n",
    "        s = set()\n",
    "        l = []\n",
    "        tks = map(prop('orth'), toks)\n",
    "        nr.shuffle(tks)\n",
    "        for w in tks:\n",
    "            s.add(w)\n",
    "            l.append(len(s))\n",
    "        return l\n",
    "    return [simgrowth_() for _ in range(nsims)]\n",
    "\n",
    "ls = simgrowth(bktksall[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for l in ls:\n",
    "    plt.plot(l, alpha=.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ls5 = simgrowth(bktks[5])\n",
    "plt.figure(figsize=(16, 10))\n",
    "for l in ls5:\n",
    "    plt.plot(l, alpha=.05)\n",
    "    \n",
    "for l in ls:\n",
    "    plt.plot(l, alpha=.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate word distributions\n",
    "For each booklength $L$, I'll be repeatedly sampling $L$ words with replacement from the book with the largest word count, book 5, and then finding the average word probability of each sample. This should give an estimate of what the average word count should be for each book, they were all drawing from the same source, given the length of each book. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sim(df, seed=None, aggfunc=None, size=None, rep=False):\n",
    "    dd = (df.sample(n=size, replace=rep, random_state=seed\n",
    "                   ).drop_duplicates('Id').Prob)\n",
    "    # with replacement, the distribution gets biased\n",
    "    # towards more low-probability words\n",
    "    return aggfunc(dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sim_gen_text(worddist=5, sizebook=1, nsims=10000,\n",
    "                 aggfunc=np.median, n_jobs=0, vb=False, rep=False):\n",
    "    pt = print if vb else (lambda *x, **_: None)\n",
    "    sizedf = get_prob_id(bktksall[sizebook])\n",
    "    size = len(sizedf)\n",
    "    if worddist == 8:\n",
    "        df = pd.concat([get_prob_id(bktksall[i]) for i in range(1, 8)])\n",
    "    else:\n",
    "        df = get_prob_id(bktksall[worddist])\n",
    "    \n",
    "    mu = aggfunc(df.drop_duplicates('Id').Prob)\n",
    "    pt(mu)\n",
    "    if (len(df) == size) and not rep:\n",
    "        return [mu for _ in range(nsims)]\n",
    "        \n",
    "    if len(df) < size:\n",
    "        raise ValueError(\"Can't sample with replacement\"\n",
    "                         \" from smaller distribution\")\n",
    "    f = delayed(sim) if n_jobs else sim\n",
    "    gen = (f(df, seed=seed, aggfunc=aggfunc, size=size, rep=rep) for seed in range(nsims))\n",
    "    if n_jobs:\n",
    "        pt('Running {} jobs...'.format(n_jobs), end=' ')\n",
    "        ret = Parallel(n_jobs=n_jobs)(gen)\n",
    "    else:\n",
    "        ret = list(gen)\n",
    "    pt('Done.')\n",
    "    sys.stdout.flush()\n",
    "    return ret "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "%time x = sim_gen_text(worddist=5, sizebook=5, nsims=100, aggfunc=np.mean, rep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@memory.cache\n",
    "def get_gen_prob_text(nsims=10000, n_jobs=-1, worddist=5, rep=False):\n",
    "    gens_mus = {\n",
    "        booknum: sim_gen_text(worddist=worddist, sizebook=booknum,\n",
    "                              nsims=nsims, aggfunc=np.mean, n_jobs=n_jobs, rep=rep)\n",
    "        for booknum in range(1, 8)\n",
    "    }\n",
    "    d = DataFrame(gens_mus)\n",
    "    return d\n",
    "\n",
    "def join_sim_act(simdf_):\n",
    "    cols = ['Val', 'Book', 'Source']\n",
    "    simdf = simdf_.copy()\n",
    "    simdf.columns.name = 'Book'\n",
    "    simdf = simdf.stack().sort_index(level='Book').reset_index(drop=0).rename(columns={0: 'Val'}).drop('level_0', axis=1)\n",
    "    simdf['Source'] = 'Simulation'\n",
    "    dboth = simdf[cols].append(uprob_books.assign(Source='Actual')[cols]).sort_values(['Book', 'Source'], ascending=True)\n",
    "    return dboth, simdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time simdf_ = get_gen_prob_text(nsims=10000, worddist=8, n_jobs=-1, rep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dboth, simdf = join_sim_act(simdf_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bothagg = dboth.groupby(['Source', 'Book',]).mean()\n",
    "bothagg.unstack('Source')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 10))\n",
    "pbothagg = ut.mod_axis(bothagg.ix['Actual'].copy().rename(columns={'Val': 'Actual'}),\n",
    "                       z.operator.add(-1))\n",
    "plt.scatter([], [], s=80, c='k', marker='x', linewidth=2)\n",
    "plt.legend(['Actual']);\n",
    "sns.violinplot('Book', 'Val', data=simdf)\n",
    "plt.scatter(pbothagg.index, pbothagg.Actual, s=80, c='k', marker='x', linewidth=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Barring some subtle errors in my simulation code (which would not surprise me at all), the violin plot above says that the actual average word probability for books 2, 5, 6 and 7 are roughly what one would expect if words were drawn at random from the whole series, based solely on the length of the book. Measuring word complexity as having a low probability, this could lead one to say that the word complexity of the first book is way below average, and the word complexity if the 3rd and 4th books are somewhat below average, with 5, 6 and 7 increasingly approaching the average. This seems to be the best evidence so far of the writing complexity increasing as Harry Potter's education progresses.\n",
    "\n",
    "The trend in increasing complexity may be clearer by plotting this difference in simulated and actual average probability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "bothagg.unstack('Source')['Val'].eval('Simulation - Actual').plot(title='Average - actual word complexity');\n",
    "plt.subplot(1, 2, 2)\n",
    "plot_corrcoef(x='Word_count', y='Mean', data=simdf.groupby(['Book']).mean().rename(columns={'Val': 'Mean'}).assign(Word_count=wc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To the right, we also see that at least the simulated values are much better estimated by a linear word count predictor (negative correlation coefficient of .985 for the simulated vs .935 for the actual averages). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DataFrame(Series({k: ((v.Val < ufreq.Mean[k]).mean() * 100).round(1) for k, v in simdf.groupby('Book')})).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence structure complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "There are different ways to measure the complexity of a sentence based on the syntactical structure, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import networkx as nx\n",
    "import pygraphviz as pgv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "G = nx.DiGraph()\n",
    "G.add_edge\n",
    "ts = bktksall[1]\n",
    "for s in ts.sents:\n",
    "    break\n",
    "s.root.head is s.root\n",
    "list(s.root.children)\n",
    "s\n",
    "s.root.\n",
    "child.n_lefts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dedupe_wrd_repr(s):\n",
    "    d = {}\n",
    "    dfd = defaultdict(int)\n",
    "    for tok in s:\n",
    "        dfd[tok.orth_] += 1\n",
    "        n = dfd[tok.orth_]\n",
    "        #print(tok.i, tok, n)\n",
    "        if n > 1:\n",
    "            d['{}[{}]'.format(tok.orth_, n)] = tok.i\n",
    "        else:\n",
    "            d[tok.orth_] = tok.i\n",
    "    return {v: k for k, v in d.items()}\n",
    "\n",
    "def add_edge(src, dst, G, reprdct=None):\n",
    "    \"\"\"Since this is a tree, append an underscore for duplicate\n",
    "    destination nodes\"\"\"\n",
    "    G.add_edge(reprdct[src.i], reprdct[dst.i])\n",
    "    \n",
    "def add_int_edge(src, dst, G, **_):\n",
    "    G.add_edge(src.i, dst.i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_graph(s, add_edge=add_edge):\n",
    "    G = pgv.AGraph(directed=True)\n",
    "    reprdct = dedupe_wrd_repr(s)\n",
    "    \n",
    "    def build_graph_(tok, i=0):\n",
    "        for c in tok.children:\n",
    "            add_edge(tok, c, G, reprdct=reprdct)\n",
    "            build_graph_(c, i=i + 2)\n",
    "        return G\n",
    "    return build_graph_(s.root)\n",
    "\n",
    "\n",
    "def show_graph(g):\n",
    "    g.draw(\"file.png\", prog='dot')\n",
    "    return Image(filename=\"file.png\") \n",
    "\n",
    "\n",
    "s = next(bktksall[1].sents)\n",
    "G = build_graph(s)\n",
    "Gi = build_graph(s, add_edge=add_int_edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_graph(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tree_depths(s, senti=None):\n",
    "    def tree_depths_(tok, i=1, vb=False,):\n",
    "        return [(i, senti)] + [t for c in tok.children\n",
    "                      for t in tree_depths_(c, i=i + 1, vb=vb)]\n",
    "    return tree_depths_(s.root, i=1)\n",
    "\n",
    "\n",
    "def sent_depth_bk(toks):\n",
    "    return DataFrame([(depth, i) for i, s in \n",
    "                      enumerate(toks.sents)\n",
    "                      for depth, senti in tree_depths(s, senti=i)],\n",
    "                    columns=['Depth', 'Sentnum'])\n",
    "\n",
    "\n",
    "sent_depths = over_books(sent_depth_bk).reset_index(drop=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sgb = (sent_depths.groupby(['Book']).Depth\n",
    "       .agg(['mean', 'median', 'max', 'idxmax'])\n",
    "       .rename(columns=str.capitalize))\n",
    "sgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "s1 = sent_depths.query('Book == 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sim_depth(s, seed=None, size=None, aggfunc=None):\n",
    "    return aggfunc(s.sample(n=size, replace=True, random_state=seed))\n",
    "\n",
    "\n",
    "@memory.cache\n",
    "def bootstrap_depths(df, by='Book', col=None, aggfunc=np.mean,\n",
    "                     nsims=10, size=1000, n_jobs=1):\n",
    "    genmkr = lambda s: (delayed(sim_depth)(s, seed=seed, aggfunc=aggfunc, size=size) for seed in range(nsims))\n",
    "    df = DataFrame({bknum: Parallel(n_jobs=n_jobs)(genmkr(gbs)) for bknum, gbs in df.groupby(by)[col]} )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time bootdepths = bootstrap_depths(sent_depths, by='Book', col='Depth', nsims=10000, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def piv(df):\n",
    "    df.columns.name = by\n",
    "    return (df.unstack().reset_index(drop=0).drop('level_1', axis=1)\n",
    "            .rename(columns={0: 'Val'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_bt_diff_(bka, bkb, df=bootdepths):\n",
    "#     return Series(df.query('Book == %s' % bka).Val.values\n",
    "#                   - df.query('Book == %s'  % bkb).Val.values)\n",
    "\n",
    "# def get_bt_diff(bka, bkb, df=bootdepths):\n",
    "#     return Series(df[bka] - df[bkb].Val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the simulated average depths of each word by book for comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ut.mod_axis(sgb, z.operator.add(-1)).Mean.plot()\n",
    "sns.violinplot(data=bootdepths);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A difference of 0 doesn't overlap much (if at all) with the distribution of the bootstrapped samples, giving us reason to believe that the difference in syntactical complexity is significant at least between books 1 and 5. This contrasts with the difference between books 1 and 2--while the the average difference is about .05 levels, the simulations make a hypothesis of 0 difference look plausible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_bt_diffs(samps, bka, bkb, subplt=1):\n",
    "    diff = samps[bka] - samps[bkb]\n",
    "    t51 = ('Average depth: Book {bka} - book {bkb} \\n(0 > difference in {perc:.2%}'\n",
    "           ' of examples)'.format(bka=bka, bkb=bkb, perc=(0 > diff).mean()))\n",
    "    plt.subplot(1, 2, subplt, title=t51)\n",
    "    diff.hist(bins=50)\n",
    "    plt.vlines(0, *plt.ylim())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 5))\n",
    "plot_bt_diffs(bootdepths, 2, 1, subplt=1)\n",
    "plot_bt_diffs(bootdepths, 5, 1, subplt=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Height"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One more metric I would like to look at is the average 'height' of the sentences by books. While I previously looked at the average depth of each word in the syntax tree, this will just talky the maximum depth of each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "maxdepth = (sent_depths.groupby(['Book', 'Sentnum']).Depth.max()\n",
    "        .reset_index(drop=0))\n",
    "sgbs = (maxdepth.groupby(['Book']).Depth\n",
    "        .agg(['mean', 'median', 'max'])\n",
    "        .rename(columns=str.capitalize)\n",
    "       )\n",
    "sgbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here again we see a bit of variation in the average sentence height by each book, but it's not obvious whether these differences are significant. Time for the bootstrap again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time bootheights = bootstrap_depths(maxdepth, by='Book', col='Depth', nsims=100000, n_jobs=-1, size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!say done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 5))\n",
    "plot_bt_diffs(bootheights, 2, 1, subplt=1)\n",
    "plot_bt_diffs(bootheights, 5, 1, subplt=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of measuring the difference in average sentence *heights* between the books, we have much more confidence that the difference in books 5 and 1 *and* between 2 and 1 were not due to chance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.violinplot(data=bootheights);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average depth of a word looks higher in book 5 than in book 1, but it's hard to tell if the difference is large enough to rule out the difference's being due to chance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!say \"I am your wretched slave, master\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epilogue: fun stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Longest words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Series([tok.orth_ for bk in bktksall.values() for tok in bk if len(tok.orth_) > 20]).value_counts(normalize=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Longest unhyphenated words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Series([tok.orth_ for bk in bktksall.values()\n",
    "        for tok in bk if len(tok.orth_) > 15\n",
    "        and '-' not in tok.orth_]).value_counts(normalize=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tallest sentence in the series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_, maxsentnum, maxbooknum = sent_depths.ix[sent_depths.Depth.idxmax()]\n",
    "[sent] = list(it.islice(bktksall[maxbooknum].sents, int(maxsentnum), int(maxsentnum + 1)))\n",
    "print(sent)\n",
    "show_graph(build_graph(sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Longest sentences\n",
    "These seem to show some parsing issues, where a sequence of quick dialogue or lyrics are interpreted as a single sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for s in [sent for _, bk in sorted(bktksall.items())[:5] for sent in bk.sents if spanlen(sent) > 200]:\n",
    "    print(s, end='\\n=======\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wd_freqs(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vcs = Series(Counter(reg_words(tt))).sort_values(ascending=False)\n",
    "bm = vcs.index.map(lambda x: len(x) > 3 and (x.lower() not in stops) and not x[0].isupper())\n",
    "vcs = vcs[bm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "R = 19\n",
    "DataFrame(list(z.partition(R, vcs.index[:R*20])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent_lens = pd.concat([sent_lens(v, i) for i, v in bktks.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Longest sentences\n",
    "Series().value_counts(normalize=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[tok for tok in bktks[5] if len(tok) > 40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 10))\n",
    "sns.boxplot(x='Book', y=0, data=wd_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 10))\n",
    "sns.boxplot(x='Book', y=0, data=sent_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 10))\n",
    "pt = sns.boxplot\n",
    "pt = sns.violinplot\n",
    "pt(x='Book', y=0, data=uncwds)\n",
    "# plt.ylim(0, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sent_lens.groupby('Book')[0].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "people = Series(ent.string.rstrip() for ent in tokens.ents if ent.label_ == 'PERSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pn[40:-40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for ent in tokens.ents:\n",
    "    print(ent, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for tok in tokens[:40]:\n",
    "    print(tok, ps.NAMES[tok.pos])\n",
    "    1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Find Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wds = tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "caps = Series([tok.string.rstrip() for tok in tokens if tok.is_title and tok.pos == ps.NOUN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import Series, DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "caps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "caps.value_counts(normalize=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tok.is_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ps.PROPN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for pos in dir(ps)[8:]:\n",
    "    print(pos)\n",
    "    if pos.isupper():\n",
    "        int(getattr(ps, pos))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[getattr(ps, pos) for pos in dir(ps) if pos.isupper()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "{getattr(ps, pos): pos for pos in dir(ps) if pos.isupper()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tok.pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!open /Users/williambeard/miniconda3/envs/hp/lib/python3.5/site-packages/spacy/en/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
